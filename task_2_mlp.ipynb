{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "TLKKsTL7sZgk",
        "outputId": "5ab4b4e8-7501-4f0b-ebbb-39ec6eff4324"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTask 2: Model 1 - The Predictive Deep Learning Model\\n\\nLoads the preprocessed data from Task 1.\\nBuilds, trains, and evaluates a Multi-Layer Perceptron (MLP) using\\nTensorFlow/Keras to predict the probability of default.\\n\\nSaves the following files:\\n- models/mlp_model.keras\\n- models/mlp_test_pred_probs.npy\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "Task 2: Model 1 - The Predictive Deep Learning Model\n",
        "\n",
        "Loads the preprocessed data from Task 1.\n",
        "Builds, trains, and evaluates a Multi-Layer Perceptron (MLP) using\n",
        "TensorFlow/Keras to predict the probability of default.\n",
        "\n",
        "Saves the following files:\n",
        "- models/mlp_model.keras\n",
        "- models/mlp_test_pred_probs.npy\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "DATA_DIR = 'data'\n",
        "MODEL_DIR = 'models'\n",
        "\n",
        "# Set Random Seeds for Reproducibility\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "KOVp9qk1vaRR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper Function ---\n",
        "def build_model(input_shape):\n",
        "    \"\"\"Defines the Keras model architecture.\"\"\"\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(input_shape,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "GuzpFxorveXC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # Create model directory if it doesn't exist\n",
        "    if not os.path.exists(MODEL_DIR):\n",
        "        os.makedirs(MODEL_DIR)\n",
        "        print(f\"Created directory: {MODEL_DIR}\")\n",
        "\n",
        "    # --- 2. Load Preprocessed Data ---\n",
        "    print(f\"Loading data from '{DATA_DIR}'...\")\n",
        "    try:\n",
        "        X_train_final = joblib.load(os.path.join(DATA_DIR, 'X_train_final.pkl'))\n",
        "        y_train = joblib.load(os.path.join(DATA_DIR, 'y_train.pkl'))\n",
        "        X_test_final = joblib.load(os.path.join(DATA_DIR, 'X_test_final.pkl'))\n",
        "        y_test = joblib.load(os.path.join(DATA_DIR, 'y_test.pkl'))\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: Processed data files not found.\")\n",
        "        return\n",
        "\n",
        "    # --- Prepare Data for TensorFlow ---\n",
        "    X_train_np = X_train_final.to_numpy()\n",
        "    y_train_np = y_train.to_numpy()\n",
        "    X_test_np = X_test_final.to_numpy()\n",
        "    y_test_np = y_test.to_numpy()\n",
        "    n_features = X_train_np.shape[1]\n",
        "    print(f\"Data converted to NumPy. Training with {n_features} features.\")\n",
        "\n",
        "    # --- Handle Class Imbalance ---\n",
        "    print(\"Calculating class weights...\")\n",
        "    weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_np), y=y_train_np)\n",
        "    class_weights = {0: weights[0], 1: weights[1]}\n",
        "    print(f\"Calculated weights: {class_weights}\")\n",
        "\n",
        "    # --- Build and Compile MLP Model ---\n",
        "    print(\"Building and compiling Keras MLP model...\")\n",
        "    model = build_model(n_features)\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=[tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "\n",
        "    # --- Train Model ---\n",
        "    print(\"Training MLP model...\")\n",
        "    history = model.fit(\n",
        "        X_train_np,\n",
        "        y_train_np,\n",
        "        epochs=20,\n",
        "        batch_size=128,\n",
        "        validation_split=0.2,\n",
        "        class_weight=class_weights,\n",
        "        verbose=1\n",
        "    )\n",
        "    print(\"MLP Training complete.\")\n",
        "\n",
        "    # --- Evaluate MLP Model ---\n",
        "    print(\"\\nEvaluating MLP model on the test set...\")\n",
        "    y_pred_probs_mlp = model.predict(X_test_np).flatten()\n",
        "    y_pred_classes_mlp = (y_pred_probs_mlp > 0.5).astype(int) # Using 0.5 threshold\n",
        "\n",
        "    auc_mlp = roc_auc_score(y_test_np, y_pred_probs_mlp)\n",
        "    f1_mlp = f1_score(y_test_np, y_pred_classes_mlp)\n",
        "\n",
        "    print(\"\\n--- MLP Evaluation Results ---\")\n",
        "    print(f\"Test Set AUC: {auc_mlp:.4f}\")\n",
        "    print(f\"Test Set F1-Score (threshold 0.5): {f1_mlp:.4f}\")\n",
        "    print(\"\\nClassification Report (threshold 0.5):\")\n",
        "    print(classification_report(y_test_np, y_pred_classes_mlp, target_names=['Fully Paid (0)', 'Defaulted (1)']))\n",
        "\n",
        "    # --- Save Model and Predictions ---\n",
        "    model_path = os.path.join(MODEL_DIR, 'mlp_model.keras')\n",
        "    preds_path = os.path.join(MODEL_DIR, 'mlp_test_pred_probs.npy')\n",
        "\n",
        "    model.save(model_path)\n",
        "    np.save(preds_path, y_pred_probs_mlp)\n",
        "    print(f\"MLP model saved to {model_path}\")\n",
        "    print(f\"MLP test predictions saved to {preds_path}\")\n",
        "\n",
        "    print(\"--- Task 2: MLP Training Complete ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Y5hhMMzvggL",
        "outputId": "bf22bf18-253a-4029-95b4-5c2d0104b22a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from 'data'...\n",
            "Data converted to NumPy. Training with 132 features.\n",
            "Calculating class weights...\n",
            "Calculated weights: {0: np.float64(0.6021198205894916), 1: np.float64(2.9481045751633985)}\n",
            "Building and compiling Keras MLP model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,625\u001b[0m (41.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,625</span> (41.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,625\u001b[0m (41.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,625</span> (41.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MLP model...\n",
            "Epoch 1/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - auc: 0.6777 - loss: 0.6469 - val_auc: 0.6793 - val_loss: 0.6278\n",
            "Epoch 2/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7010 - loss: 0.6328 - val_auc: 0.6824 - val_loss: 0.6352\n",
            "Epoch 3/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7040 - loss: 0.6305 - val_auc: 0.6832 - val_loss: 0.6268\n",
            "Epoch 4/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7057 - loss: 0.6295 - val_auc: 0.6839 - val_loss: 0.6197\n",
            "Epoch 5/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc: 0.7066 - loss: 0.6283 - val_auc: 0.6841 - val_loss: 0.6182\n",
            "Epoch 6/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc: 0.7088 - loss: 0.6269 - val_auc: 0.6842 - val_loss: 0.6220\n",
            "Epoch 7/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - auc: 0.7092 - loss: 0.6267 - val_auc: 0.6842 - val_loss: 0.6239\n",
            "Epoch 8/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc: 0.7096 - loss: 0.6260 - val_auc: 0.6850 - val_loss: 0.6289\n",
            "Epoch 9/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7107 - loss: 0.6255 - val_auc: 0.6839 - val_loss: 0.6208\n",
            "Epoch 10/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7113 - loss: 0.6250 - val_auc: 0.6840 - val_loss: 0.6197\n",
            "Epoch 11/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7128 - loss: 0.6238 - val_auc: 0.6837 - val_loss: 0.6262\n",
            "Epoch 12/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7120 - loss: 0.6246 - val_auc: 0.6838 - val_loss: 0.6249\n",
            "Epoch 13/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc: 0.7130 - loss: 0.6237 - val_auc: 0.6836 - val_loss: 0.6235\n",
            "Epoch 14/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7140 - loss: 0.6232 - val_auc: 0.6835 - val_loss: 0.6238\n",
            "Epoch 15/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7146 - loss: 0.6226 - val_auc: 0.6839 - val_loss: 0.6210\n",
            "Epoch 16/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7141 - loss: 0.6228 - val_auc: 0.6832 - val_loss: 0.6174\n",
            "Epoch 17/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - auc: 0.7151 - loss: 0.6224 - val_auc: 0.6831 - val_loss: 0.6155\n",
            "Epoch 18/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7152 - loss: 0.6220 - val_auc: 0.6828 - val_loss: 0.6216\n",
            "Epoch 19/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7170 - loss: 0.6210 - val_auc: 0.6827 - val_loss: 0.6185\n",
            "Epoch 20/20\n",
            "\u001b[1m2820/2820\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - auc: 0.7166 - loss: 0.6209 - val_auc: 0.6827 - val_loss: 0.6183\n",
            "MLP Training complete.\n",
            "\n",
            "Evaluating MLP model on the test set...\n",
            "\u001b[1m27947/27947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2ms/step\n",
            "\n",
            "--- MLP Evaluation Results ---\n",
            "Test Set AUC: 0.7166\n",
            "Test Set F1-Score (threshold 0.5): 0.4508\n",
            "\n",
            "Classification Report (threshold 0.5):\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Fully Paid (0)       0.88      0.62      0.73    702191\n",
            " Defaulted (1)       0.33      0.69      0.45    192099\n",
            "\n",
            "      accuracy                           0.64    894290\n",
            "     macro avg       0.61      0.66      0.59    894290\n",
            "  weighted avg       0.76      0.64      0.67    894290\n",
            "\n",
            "MLP model saved to models/mlp_model.keras\n",
            "MLP test predictions saved to models/mlp_test_pred_probs.npy\n",
            "--- Task 2: MLP Training Complete ---\n"
          ]
        }
      ]
    }
  ]
}