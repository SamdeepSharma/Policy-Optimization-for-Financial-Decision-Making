{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Q2qZ9cbosO2Q",
        "outputId": "e5df7c8a-cce0-46ff-bb4f-1f8fc35f55ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTask 4: Analysis, Comparison, and Future Steps\\n\\nLoads the pre-trained MLP model (Task 2) and CQL agent (Task 3).\\nLoads the preprocessed test data (Task 1).\\nCompares the models on two fronts:\\n1.  Predictive Performance (MLP): AUC, F1-Score.\\n2.  Decision-Making Value (CQL): Estimated Policy Value ($) vs. baselines.\\n\\nPrints a final report comparing the approaches.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\"\"\"\n",
        "Task 4: Analysis, Comparison, and Future Steps\n",
        "\n",
        "Loads the pre-trained MLP model (Task 2) and CQL agent (Task 3).\n",
        "Loads the preprocessed test data (Task 1).\n",
        "Compares the models on two fronts:\n",
        "1.  Predictive Performance (MLP): AUC, F1-Score.\n",
        "2.  Decision-Making Value (CQL): Estimated Policy Value ($) vs. baselines.\n",
        "\n",
        "Prints a final report comparing the approaches.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d3rlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6ErFDmtKJdM",
        "outputId": "5564644d-0997-49de-891e-91fc9d8deb12"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: d3rlpy in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: torch>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (4.67.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (3.15.1)\n",
            "Requirement already satisfied: gym>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (0.26.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (8.3.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (4.15.0)\n",
            "Requirement already satisfied: structlog in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (25.5.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (0.4.6)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (0.6.7)\n",
            "Requirement already satisfied: gymnasium==1.0.0 in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from d3rlpy) (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.0.0->d3rlpy) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.0.0->d3rlpy) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium==1.0.0->d3rlpy) (0.0.4)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from gym>=0.26.0->d3rlpy) (0.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.5.0->d3rlpy) (3.4.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->d3rlpy) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->d3rlpy) (0.9.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->d3rlpy) (3.6.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.12/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->d3rlpy) (25.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.5.0->d3rlpy) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->d3rlpy) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.5.0->d3rlpy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import d3rlpy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import roc_auc_score, f1_score, classification_report\n",
        "import joblib\n",
        "import os\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- 0. Configuration ---\n",
        "RANDOM_SEED = 42\n",
        "DATA_DIR = 'data'\n",
        "MODEL_DIR = 'models'\n",
        "\n",
        "# Set Random Seed\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "DPkdLd24tZ2m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    # --- Load Data and Models ---\n",
        "    print(\"Step 1: Loading all data and trained models...\")\n",
        "    try:\n",
        "        # Load test data\n",
        "        X_test_final = joblib.load(os.path.join(DATA_DIR, 'X_test_final.pkl'))\n",
        "        y_test = joblib.load(os.path.join(DATA_DIR, 'y_test.pkl'))\n",
        "\n",
        "        # Load data for reward calculation\n",
        "        df_model = joblib.load(os.path.join(DATA_DIR, 'df_model_for_rewards.pkl'))\n",
        "        test_indices = joblib.load(os.path.join(DATA_DIR, 'test_indices.pkl'))\n",
        "\n",
        "        # Load data signature for building CQL\n",
        "        X_train_final = joblib.load(os.path.join(DATA_DIR, 'X_train_final.pkl'))\n",
        "\n",
        "        # Load trained MLP model\n",
        "        model_mlp = keras.models.load_model(os.path.join(MODEL_DIR, 'mlp_model.keras'))\n",
        "\n",
        "        # Load MLP predictions\n",
        "        y_pred_probs_mlp = np.load(os.path.join(MODEL_DIR, 'mlp_test_pred_probs.npy'))\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading file: {e}\")\n",
        "        print(\"Please ensure Tasks 1 and 2 have been run successfully.\")\n",
        "        return\n",
        "\n",
        "    print(\"Data and MLP model loaded successfully.\")\n",
        "\n",
        "    # --- 2. Load CQL Agent (Robust Method) ---\n",
        "    print(\"Loading CQL agent using robust method...\")\n",
        "    try:\n",
        "\n",
        "      dummy_obs = X_train_final.to_numpy()[:2]\n",
        "\n",
        "      if len(dummy_obs) < 2:\n",
        "          dummy_obs = np.vstack([dummy_obs, dummy_obs])\n",
        "\n",
        "      dummy_actions = np.array([0, 1], dtype=np.int32)\n",
        "\n",
        "      dataset = d3rlpy.dataset.MDPDataset(\n",
        "          observations=dummy_obs,\n",
        "          actions=dummy_actions,\n",
        "          rewards=np.zeros(2),\n",
        "          terminals=np.ones(2)\n",
        "      )\n",
        "\n",
        "      # 1. Re-instantiate the same config as in Task 3\n",
        "      cql_config = d3rlpy.algos.DiscreteCQLConfig(\n",
        "          batch_size=128,\n",
        "          learning_rate=6.25e-5,\n",
        "          alpha=1.0,\n",
        "      )\n",
        "      cql_agent = cql_config.create(device=False)\n",
        "\n",
        "      # 2. Build the agent with the *corrected* dataset signature\n",
        "      cql_agent.build_with_dataset(dataset)\n",
        "\n",
        "      # 3. Load the saved model weights\n",
        "      model_path = os.path.join(MODEL_DIR, 'cql_agent.d3')\n",
        "      cql_agent.load_model(model_path)\n",
        "\n",
        "      print(f\"CQL agent weights loaded manually from {model_path}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "      print(f\"Error loading CQL model: {e}\")\n",
        "      print(f\"Please ensure `task_3_cql.py` has run and {model_path} exists.\")\n",
        "      return\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred while loading CQL model: {e}\")\n",
        "      return\n",
        "\n",
        "\n",
        "    # Convert test data to NumPy\n",
        "    observations_test = X_test_final.to_numpy()\n",
        "    y_test_np = y_test.to_numpy()\n",
        "\n",
        "    # --- Evaluate Model 1 (MLP) ---\n",
        "    print(\"\\n--- üìä Model 1: Supervised DL (MLP) Evaluation ---\")\n",
        "    print(\"Objective: Predict default probability.\")\n",
        "\n",
        "    y_pred_classes_mlp = (y_pred_probs_mlp > 0.5).astype(int)\n",
        "    auc_mlp = roc_auc_score(y_test_np, y_pred_probs_mlp)\n",
        "    f1_mlp = f1_score(y_test_np, y_pred_classes_mlp)\n",
        "\n",
        "    print(f\"  > Test Set AUC: {auc_mlp:.4f}\")\n",
        "    print(f\"  > Test Set F1-Score (threshold 0.5): {f1_mlp:.4f}\")\n",
        "    print(\"\\n  Classification Report (threshold 0.5):\")\n",
        "    print(classification_report(y_test_np, y_pred_classes_mlp, target_names=['  Fully Paid (0)', '  Defaulted (1)']))\n",
        "    print(\"  MLP Conclusion: The model provides a probabilistic risk score (AUC).\")\n",
        "    print(\"  Its F1-score shows its ability to balance precision/recall for default detection.\")\n",
        "\n",
        "    # --- Evaluate Model 2 (CQL Agent) ---\n",
        "    print(\"\\n--- üìä Model 2: Offline RL (CQL) Evaluation ---\")\n",
        "    print(\"Objective: Learn a policy to maximize financial return.\")\n",
        "\n",
        "    # Get Q-values for both actions on the test set\n",
        "    print(\"  Predicting Q-values for 'Deny' (0) and 'Approve' (1)...\")\n",
        "    q_values_deny = cql_agent.predict_value(observations_test, np.zeros(len(observations_test), dtype=np.int32))\n",
        "    q_values_approve = cql_agent.predict_value(observations_test, np.ones(len(observations_test), dtype=np.int32))\n",
        "\n",
        "    # RL Agent's policy: Choose action with higher Q-value\n",
        "    agent_policy_actions = (q_values_approve > q_values_deny).astype(int) # 1 if Approve > Deny, 0 otherwise\n",
        "\n",
        "    # Calculate raw rewards for the test set for analysis\n",
        "    rewards_test_raw = np.where(\n",
        "        df_model.loc[test_indices, 'is_default'] == 0,\n",
        "        df_model.loc[test_indices, 'total_rec_int'],\n",
        "        df_model.loc[test_indices, 'total_pymnt'] - df_model.loc[test_indices, 'loan_amnt']\n",
        "    )\n",
        "\n",
        "    # --- Calculate and Compare Policy Values (OPE) ---\n",
        "    print(\"\\n--- üìà Estimated Policy Value (EPV) Comparison ---\")\n",
        "\n",
        "    # Baseline 1: Historical Policy (Always Approve)\n",
        "    historical_policy_value = rewards_test_raw.mean()\n",
        "\n",
        "    # Baseline 2: Always Deny Policy\n",
        "    always_deny_policy_value = 0.0\n",
        "\n",
        "    # Policy 3: RL Agent's Policy\n",
        "    rl_policy_rewards = np.where(agent_policy_actions == 1, rewards_test_raw, 0)\n",
        "    rl_policy_value = rl_policy_rewards.mean()\n",
        "\n",
        "    print(f\"  > Baseline (Historical - Approve All): ${historical_policy_value:,.2f} avg profit/loan\")\n",
        "    print(f\"  > Baseline (Always Deny):              ${always_deny_policy_value:,.2f} avg profit/loan\")\n",
        "    print(f\"  > New RL (CQL) Policy Value:           ${rl_policy_value:,.2f} avg profit/loan\")\n",
        "\n",
        "    if rl_policy_value > historical_policy_value and rl_policy_value > always_deny_policy_value:\n",
        "        print(\"\\n  ‚úÖ RL Agent Policy is the most profitable on the test set.\")\n",
        "    elif historical_policy_value > rl_policy_value and historical_policy_value > always_deny_policy_value:\n",
        "        print(\"\\n  ‚ö†Ô∏è Historical (Approve All) Policy remains the most profitable.\")\n",
        "    else:\n",
        "        print(\"\\n  ‚ö†Ô∏è Always Deny Policy is the most profitable (this indicates a poor-quality loan book).\")\n",
        "\n",
        "    if rl_policy_value == historical_policy_value:\n",
        "         print(\"  NOTE: RL agent policy value is identical to historical, suggesting it learned to 'Always Approve'.\")\n",
        "         print(\"  This is a common result of selection bias in accepted-only datasets.\")\n",
        "\n",
        "    # --- Policy Behavior Breakdown ---\n",
        "    policy_comparison = pd.DataFrame({\n",
        "        'RL_Policy': pd.Series(agent_policy_actions, index=y_test.index).map({0: 'Deny', 1: 'Approve'}),\n",
        "        'Historical_Status': y_test.map({0: 'Paid', 1: 'Defaulted'}),\n",
        "        'Actual_Profit_Loss': rewards_test_raw\n",
        "    })\n",
        "\n",
        "    print(\"\\n--- RL Policy Decision Breakdown (Test Set) ---\")\n",
        "    print(policy_comparison.groupby(['RL_Policy', 'Historical_Status']).agg(\n",
        "        count=('Actual_Profit_Loss', 'size'),\n",
        "        avg_profit_loss=('Actual_Profit_Loss', 'mean')\n",
        "    ).round(2))\n",
        "\n",
        "    print(\"\\n--- End of Analysis ---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByvUALs4HJif",
        "outputId": "0b6c1d19-9af0-4ce4-ef13-9d3269e99684"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Loading all data and trained models...\n",
            "Data and MLP model loaded successfully.\n",
            "Loading CQL agent using robust method...\n",
            "\u001b[2m2025-10-30 09:41.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int32')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float64')], shape=[(132,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float64')], shape=[(1,)])\u001b[0m\n",
            "\u001b[2m2025-10-30 09:41.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
            "\u001b[2m2025-10-30 09:41.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n",
            "CQL agent weights loaded manually from models/cql_agent.d3\n",
            "\n",
            "--- üìä Model 1: Supervised DL (MLP) Evaluation ---\n",
            "Objective: Predict default probability.\n",
            "  > Test Set AUC: 0.7165\n",
            "  > Test Set F1-Score (threshold 0.5): 0.4512\n",
            "\n",
            "  Classification Report (threshold 0.5):\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "  Fully Paid (0)       0.88      0.65      0.75    702191\n",
            "   Defaulted (1)       0.34      0.66      0.45    192099\n",
            "\n",
            "        accuracy                           0.66    894290\n",
            "       macro avg       0.61      0.66      0.60    894290\n",
            "    weighted avg       0.76      0.66      0.68    894290\n",
            "\n",
            "  MLP Conclusion: The model provides a probabilistic risk score (AUC).\n",
            "  Its F1-score shows its ability to balance precision/recall for default detection.\n",
            "\n",
            "--- üìä Model 2: Offline RL (CQL) Evaluation ---\n",
            "Objective: Learn a policy to maximize financial return.\n",
            "  Predicting Q-values for 'Deny' (0) and 'Approve' (1)...\n",
            "\n",
            "--- üìà Estimated Policy Value (EPV) Comparison ---\n",
            "  > Baseline (Historical - Approve All): $-191.86 avg profit/loan\n",
            "  > Baseline (Always Deny):              $0.00 avg profit/loan\n",
            "  > New RL (CQL) Policy Value:           $-191.86 avg profit/loan\n",
            "\n",
            "  ‚ö†Ô∏è Always Deny Policy is the most profitable (this indicates a poor-quality loan book).\n",
            "  NOTE: RL agent policy value is identical to historical, suggesting it learned to 'Always Approve'.\n",
            "  This is a common result of selection bias in accepted-only datasets.\n",
            "\n",
            "--- RL Policy Decision Breakdown (Test Set) ---\n",
            "                              count  avg_profit_loss\n",
            "RL_Policy Historical_Status                         \n",
            "Approve   Defaulted          192099         -8080.32\n",
            "          Paid               702191          1966.19\n",
            "\n",
            "--- End of Analysis ---\n"
          ]
        }
      ]
    }
  ]
}